{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a878f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data loaded from ./data/clean_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load clean dataset & prepare features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Load clean data\n",
    "df = pd.read_csv(\"../data/clean_data.csv\")\n",
    "print(\"Clean data loaded from ./data/clean_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c802ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28156 entries, 0 to 28155\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   Product             28156 non-null  category\n",
      " 1   Issue               28156 non-null  category\n",
      " 2   Company response    28156 non-null  category\n",
      " 3   Consumer disputed?  28156 non-null  category\n",
      " 4   Timely response?    28156 non-null  category\n",
      "dtypes: category(5)\n",
      "memory usage: 141.2 KB\n",
      "None\n",
      "           Product                                     Issue  \\\n",
      "0  Debt collection                     Communication tactics   \n",
      "1  Debt collection     Cont'd attempts collect debt not owed   \n",
      "2         Mortgage  Application, originator, mortgage broker   \n",
      "3      Credit card                                     Other   \n",
      "4  Debt collection     Cont'd attempts collect debt not owed   \n",
      "\n",
      "          Company response Consumer disputed? Timely response?  \n",
      "0              In progress            Missing              Yes  \n",
      "1  Closed with explanation            Missing              Yes  \n",
      "2  Closed with explanation                Yes              Yes  \n",
      "3              In progress            Missing              Yes  \n",
      "4              In progress            Missing              Yes  \n",
      "Training set shape: (22524, 4)\n",
      "Testing set shape: (5632, 4)\n"
     ]
    }
   ],
   "source": [
    "# Convert suitable columns to categorical dtype\n",
    "cat_cols = [\"Product\", \"Issue\", \"Company response\", \"Consumer disputed?\", \"Timely response?\"]\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "\n",
    "# For missing values, fill with a new category 'Missing' in categorical columns\n",
    "for col in cat_cols:\n",
    "    if df[col].isna().any():\n",
    "        df[col] = df[col].cat.add_categories(\"Missing\").fillna(\"Missing\")\n",
    "\n",
    "# Confirm transformation\n",
    "print(df[cat_cols].info())\n",
    "print(df[cat_cols].head())\n",
    "\n",
    "# Prepare features and target\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Feature columns (excluding target)\n",
    "feature_cols = [\"Product\", \"Issue\", \"Company response\", \"Consumer disputed?\"]\n",
    "target_col = \"Timely response?\"\n",
    "\n",
    "# Separate features and target\n",
    "X = df[feature_cols]\n",
    "y = df[target_col].cat.codes  # Encoding target as 0/1\n",
    "\n",
    "# Train-test split with stratification on target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Display shapes to confirm\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3768f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model comparison (mean ± std):\n",
      "\n",
      "Logistic Regression:\n",
      "  f1: 0.8664 ± 0.0024\n",
      "  precision: 0.9878 ± 0.0012\n",
      "  recall: 0.7717 ± 0.0037\n",
      "  roc_auc: 0.7639 ± 0.0247\n",
      "\n",
      "Random Forest:\n",
      "  f1: 0.9293 ± 0.0140\n",
      "  precision: 0.9899 ± 0.0014\n",
      "  recall: 0.8760 ± 0.0260\n",
      "  roc_auc: 0.8614 ± 0.0117\n",
      "\n",
      "XGBoost:\n",
      "  f1: 0.9099 ± 0.0200\n",
      "  precision: 0.9913 ± 0.0017\n",
      "  recall: 0.8416 ± 0.0360\n",
      "  roc_auc: 0.8845 ± 0.0137\n",
      "\n",
      "Best model: Random Forest\n",
      "\n",
      "Test Set Performance for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.65      0.19       142\n",
      "           1       0.99      0.87      0.93      5490\n",
      "\n",
      "    accuracy                           0.86      5632\n",
      "   macro avg       0.55      0.76      0.56      5632\n",
      "weighted avg       0.97      0.86      0.91      5632\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  92   50]\n",
      " [ 722 4768]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train baseline models with cross-validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Create encoder\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "        ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42))\n",
    "    ]),\n",
    "    \"Random Forest\": Pipeline([\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42))\n",
    "    ]),\n",
    "    \"XGBoost\": Pipeline([\n",
    "        ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)),\n",
    "        ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', \n",
    "                                   scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(), \n",
    "                                   random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Stratified 5-fold CV setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Metrics to evaluate\n",
    "scoring = {\n",
    "    'f1': make_scorer(f1_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "# Evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    cv_results = cross_validate(model, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    results[name] = {metric: (np.mean(cv_results[f'test_{metric}']), np.std(cv_results[f'test_{metric}'])) for metric in scoring}\n",
    "\n",
    "# Display results\n",
    "print(\"Model comparison (mean ± std):\\n\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    for metric, (mean_score, std_score) in metrics.items():\n",
    "        print(f\"  {metric}: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Select best model based on F1 score\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['f1'][0])\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "# Train the best model on full training data\n",
    "best_pipeline = models[best_model_name]\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "print(f\"\\nTest Set Performance for {best_model_name}:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d585c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline (Random Forest) saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained pipeline\n",
    "import os\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "joblib.dump(best_pipeline, '../models/best_pipeline.pkl')\n",
    "\n",
    "# Also save the feature columns for reference\n",
    "joblib.dump(feature_cols, '../models/feature_columns.pkl')\n",
    "\n",
    "print(f\"\\nBest pipeline ({best_model_name}) saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
